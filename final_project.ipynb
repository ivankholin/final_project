{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаемые библиотеки\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from bpemb import BPEmb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 3000\n",
    "emb_dim = 100\n",
    "max_len = 200 # TODO посчитать максимальную длинну выборки\n",
    "buffer_size = 101# размер буфера данных в батчах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_ru = BPEmb(lang='ru', vs=vocab_size , dim=emb_dim)\n",
    "\n",
    "# bpemb_ru.encode_ids('.,!?:;')\n",
    "#>>> [2898, 679, 2978, 2985, 2947, 2963]\n",
    "def load_emb_matrix(bpemb= bpemb_ru, dtype=np.float32):\n",
    "    return bpemb.emb.vectors.astype(dtype)\n",
    "\n",
    "def parse_fn(line, bpemb = bpemb_ru):\n",
    "\n",
    "    sequence = np.array(bpemb.encode_ids(line)).astype(np.int32)\n",
    "\n",
    "    feature = np.hstack(([1],sequence[:-1]))\n",
    "    \n",
    "    labels = ( #TODO изменить кастыли с циферками 2898-, 679-. 2978-! 2985-? 2947-: 2963-; \n",
    "              (sequence == 2898)*1 + \n",
    "              (sequence == 679)*2 + \n",
    "              (sequence == 2978)*3 + \n",
    "              (sequence == 2985)*4 + \n",
    "              (sequence == 2947)*5 + \n",
    "              (sequence == 2963)*6\n",
    "             ).astype(np.int32) \n",
    "    \n",
    "    mask = ((labels == 0)*1 + (labels != 0)).astype(np.float32)\n",
    "    \n",
    "    return (feature, len(feature)), (labels, len(labels), mask)\n",
    "\n",
    "\n",
    "def generator_fn(data_file_url):\n",
    "    with open(data_file_url, 'r') as file:\n",
    "        for row in file:\n",
    "            yield parse_fn(row[:-1])\n",
    "\n",
    "\n",
    "def input_fn(data_file_url, params, mode):\n",
    "\n",
    "    shapes = (([None], ()), ([None], (), [None]))\n",
    "    types = ((tf.int32, tf.int32), (tf.int32, tf.int32, tf.float32))\n",
    "    defaults = ((1, 0), (1, 0, 0.))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(lambda : generator_fn(data_file_url),\n",
    "                                             output_shapes=shapes, output_types=types)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=params['train_size'], reshuffle_each_iteration=True)\n",
    "        dataset = dataset.repeat(params['num_epochs'])\n",
    "    \n",
    "    \n",
    "    dataset = dataset.repeat(params['num_epochs'])\n",
    "    return (dataset.padded_batch(params['batch_size'], shapes).prefetch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель\n",
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    sequences, lengths = features\n",
    "    current_butch_size = tf.shape(sequences)[0]\n",
    "\n",
    "    # матрица эмбеддингов decoder-а\n",
    "    embeddings = tf.Variable(initial_value = load_emb_matrix() ,trainable=False)\n",
    "    \n",
    "    # decoder\n",
    "    cell  = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(num_units=params['lstm_hidden_dim']) \n",
    "                          for _ in range(params['num_layers'])])\n",
    "    \n",
    "    # началное состояние\n",
    "    initial_state = tuple([tf.tile(tf.constant([[0]], tf.float32), [current_butch_size, params['lstm_hidden_dim']]) \n",
    "                           for _ in range(params['num_layers'])]) \n",
    "\n",
    "        \n",
    "\n",
    "    sequences_embedded = tf.nn.embedding_lookup(params=embeddings, ids=sequences)\n",
    "\n",
    "    train_helper = tf.contrib.seq2seq.TrainingHelper(inputs=sequences_embedded, \n",
    "                                                      sequence_length=lengths)\n",
    "\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(cell=cell, \n",
    "                                              helper=train_helper, \n",
    "                                              initial_state=initial_state\n",
    "                                             )\n",
    "\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder,\n",
    "                                                      maximum_iterations=params['max_iter'], \n",
    "                                                      impute_finished=True,\n",
    "                                                      )\n",
    "\n",
    "    \n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    dropout = tf.layers.dropout(inputs=outputs.rnn_output, \n",
    "                                rate= 1 - params['dropout_rate'], \n",
    "                                training=training)\n",
    "\n",
    "    dense = tf.layers.dense(dropout, params['output_vocab_size'])\n",
    "    \n",
    "\n",
    "    logits = dense\n",
    "    sample_id = tf.argmax(logits, 2)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'sequences': sequences,\n",
    "            'prediction': sample_id,\n",
    "            'lengths': lengths\n",
    "        }\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    else:\n",
    "        target, target_lengths, mask = labels\n",
    "\n",
    "        #mask = tf.sequence_mask(lengths, dtype=tf.float32)\n",
    "\n",
    "        metrics = {\n",
    "            'acc': tf.metrics.accuracy(target, sample_id, mask),\n",
    "            #'f1_score' : tf.contrib.metrics.f1_score(target, sample_id, mask),\n",
    "        }\n",
    "\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(logits=logits, \n",
    "                                                targets=target, \n",
    "                                                weights=mask, \n",
    "                                                average_across_timesteps=True, \n",
    "                                                average_across_batch=True)\n",
    "\n",
    "        # в режиме eval возвращаем усреднённый лосс\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        # в режиме train ещё и обновляем обучаемые параметры\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer\n",
    "            optimizer = optimizer(learning_rate=params['learning_rate'])\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'project1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f525680d0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'output_vocab_size': 7,\n",
    "    'train_size': 256*buffer_size,\n",
    "    'num_layers': 2,\n",
    "    'embedding_dim': emb_dim,\n",
    "    'dropout_rate': 0.2,\n",
    "    'lstm_hidden_dim': 300,\n",
    "    'max_iter': max_len,\n",
    "    'batch_size': 256,\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 1e-3\n",
    "}\n",
    "\n",
    "config = tf.estimator.RunConfig(model_dir='project1',\n",
    "                                save_checkpoints_steps = 200,\n",
    "                               save_checkpoints_secs = None)\n",
    "model = tf.estimator.Estimator(model_fn=model_fn, params=params, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-4-230e8d365e71>:45: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into project1/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.940601, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.06829\n",
      "INFO:tensorflow:loss = 0.18132442, step = 101 (93.609 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into project1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.03941\n",
      "INFO:tensorflow:loss = 0.1616047, step = 201 (96.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.0702\n",
      "INFO:tensorflow:loss = 0.13889553, step = 301 (93.441 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into project1/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.05828\n",
      "INFO:tensorflow:loss = 0.14392494, step = 401 (94.493 sec)\n"
     ]
    }
   ],
   "source": [
    "model.train(lambda: input_fn('flibusta_full_train.txt', params=params, mode='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-12-16:01:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from project1/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-12-16:01:46\n",
      "INFO:tensorflow:Saving dict for global step 1800: acc = 0.6312711, global_step = 1800, loss = 1.1486834\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: project1/model.ckpt-1800\n"
     ]
    }
   ],
   "source": [
    "# обучение и валидация\n",
    "eval_result = model.evaluate(lambda: input_fn('eval.txt', params=params, mode='eval'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from project1/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "в середине разговора про политические действия анна павловна разгорячи\n",
      "в середине разговора? про политические? действия? анна? павлов?на? разгорячи\n",
      "анна павловна почти закрыла глаза в знак того что ни она ни кто другой не могут судить про то что угодно или нравится императри\n",
      "анна! павлов!на? почти закрыла? глаза? в знак? того что? ни она ни кто друго?й не могут? судить? про то что? угодно или нрави?тся? импера?три?\n",
      "князь наклонился в знак уважения и признатель\n",
      "князь! наклони!лся! в знак! уважения! и признатель\n",
      "и она улыбнулась своею восторженною улыб\n",
      "и она? улыб?ну?лась? сво?е?ю? восто?р?жен?но?ю? улы?б?\n",
      "князь не отвечал но она молча значительно глядя на него ждала ответа князь василий поморщи\n",
      "князь! не отвечал! но она молча значительно глядя на него жда!ла! ответа князь! василий поморщи\n",
      "и она развела руками чтобы показать свое в кружевах серенькое изящное платье немного ниже грудей опоясанное широкою лен\n",
      "и она? развела? руками? чтобы? показать? сво?е? в круже?ва?х? сере?нь?кое? изя?щ?ное? пла?ть?е? нем?ного? ниже? гру?дей? о?по?я?са?нное? широ?ко?ю? ле?н?\n",
      "виконт поклонился в знак покорности и учтиво улыбнулся анна павловна сделала круг около виконта и пригласила всех слушать его расска\n",
      "виконт! поклонился? в знак? покорности? и учтиво улыбнулся? анна? пав?лов?на? сделала? круг около виконта и пригласила всех слушать его расска\n",
      "виконт хотел уже начать свой рассказ и тонко улыбну\n",
      "виконт! хотел? уже? начать? свой рассказ? и тон?ко? улыб?ну\n",
      "княгиня улыбаясь и говоря со всеми вдруг произвела перестановку и усевшись весело оправи\n",
      "княги?ня? улыба!я!сь! и говоря со все!ми! вдруг! произвела! перестановку и усевшись весело оправи\n",
      "князь ипполит перенес ей ридикюль перешел за нею и близко придвинув к ней кресло сел подле не\n",
      "князь! ипполит! перенес ей! риди!к!ю!ль перешел за нею! и близко придвинув к ней кресло сел подле не\n"
     ]
    }
   ],
   "source": [
    "# дешифровка \n",
    "d = {1:2898, 2:679, 3:2978, 4:2985, 5:2947, 6:2963}\n",
    "for x in model.predict(lambda: input_fn('test.txt', params=params, mode='predicted')):\n",
    "    a = []\n",
    "    for i in range(x['lengths']):\n",
    "        a.append(x['sequences'][i])\n",
    "        if x['prediction'][i] != 0:\n",
    "            a.append(d[x['prediction'][i]])\n",
    "    print(bpemb_ru.decode_ids(x['sequences'][:x['lengths']]))\n",
    "    print(bpemb_ru.decode_ids(np.array(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'князь! ипполит! перенес ей! риди!к!ю!ль перешел за нею! и близко придвинув к ней кресло сел подле не'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_ru.decode_ids(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'виконт хотел уже начать свой рассказ и тонко улыбнулся'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpemb_ru.decode_ids([1,  264,  436, 2906,  333,   23, 2908, 1100,  376,  101, 1678,\n",
    "       2168, 2920,   15,  152, 2903,    8,   53,  293, 2918,  147,  225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
